{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path, walk\n",
    "from PyPDF2 import PdfFileReader\n",
    "from PyPDF2.utils import PdfReadError\n",
    "from collections import defaultdict\n",
    "from re import compile, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_to_nums = compile(\"([a-zA-Z]+)([0-9]+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_bad(string):\n",
    "    return sub('\\t|\\xa0', '', string.replace('\\n', ' ')).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encounter_utility_file(filename):\n",
    "    if any(name in filename for name in ['DS_Store', 'zip']):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TITLE = 'title'\n",
    "AUTHOR = 'author'\n",
    "NAME = 'name'\n",
    "AFFILIATION = 'affiliation'\n",
    "EMAIL = 'email'\n",
    "TEXT = 'text'\n",
    "REFERENCES = 'references'\n",
    "REF_MARKER = '\\xa0 ЛИТЕРАТУРА \\xa0'\n",
    "KEYWORDS_MARKER = 'Ключевые слова'\n",
    "KEYWORDS = 'keywords'\n",
    "ABSTRACT = 'abstract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_paper_data(content, conference, year):\n",
    "    if conference == 'Dialogue' and (year == '2000' or year == '2001'):\n",
    "        parse_dialogue_2000_2001(content.split('\\n'), conference, year)\n",
    "    elif conference == 'Dialogue' and year == '2002':\n",
    "        parse_dialogue_2002(content, conference, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dialogue_2000_2001(content, conference, year):\n",
    "    parsed_data = {}\n",
    "    parsed_data[TITLE] = content[0]\n",
    "    parsed_data[AUTHOR] = []\n",
    "    author_dict = {}\n",
    "    author_dict[NAME] = content[2]\n",
    "    author_dict[AFFILIATION] = content[3]\n",
    "    author_dict[EMAIL] = content[4]\n",
    "    parsed_data[AUTHOR].append(author_dict)\n",
    "    parsed_data[TEXT] = remove_bad(' '.join(content[5:])).lower()\n",
    "    parsed_data[KEYWORDS] = '-'\n",
    "    parsed_data[ABSTRACT] = '-'\n",
    "    data[conference][year].append(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dialogue_2002(content, conference, year):\n",
    "    parsed_data = {}\n",
    "    parsed_data[TITLE] = content.strip().split('\\n')[0]\n",
    "    parsed_data[AUTHOR] = []\n",
    "    for author in content.strip().replace(parsed_data[TITLE], '').split(KEYWORDS_MARKER)[0].strip().split('\\xa0'):\n",
    "        split = author.strip().split('\\n')\n",
    "        author_dict = {}\n",
    "        author_dict[NAME] = split[0]\n",
    "        author_dict[AFFILIATION] = split[1]\n",
    "        author_dict[EMAIL] = split[2] \n",
    "        parsed_data[AUTHOR].append(author_dict)\n",
    "    parsed_data[KEYWORDS] = content.strip().replace(parsed_data[TITLE], '').split(KEYWORDS_MARKER)[1].split('\\n', 1)[0].strip()\n",
    "    parsed_data[ABSTRACT] = content.strip().replace(parsed_data[TITLE], '').split(KEYWORDS_MARKER)[1].split('\\n', 1)[1].split('\\n', 1)[0]\n",
    "    parsed_data[TEXT] = remove_bad(content.strip().replace(parsed_data[TITLE], '').split(KEYWORDS_MARKER)[1].split('\\n', 1)[1].split('\\n', 1)[1])\n",
    "    data[conference][year].append(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_files(root):\n",
    "    for root, dirs, files in walk(root, 'r'):\n",
    "        for file in files:\n",
    "            with open(path.join(root, file), 'rb') as input_stream:\n",
    "                if encounter_utility_file(file):\n",
    "                    continue\n",
    "                conference = str(root + file).split('data/')[1].split('/')[0]\n",
    "                year = str(root).split('data/')[1].split('/')[1]\n",
    "                try:\n",
    "                    add_paper_data(input_stream.read().decode('utf-8').split('\\n'), conference, year)\n",
    "                except UnicodeDecodeError:\n",
    "                    continue # remove\n",
    "                    reader = PdfFileReader(input_stream)\n",
    "                    data[conference][year].append(reader.getPage(0).extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(lambda: defaultdict(lambda: []))\n",
    "contents = []\n",
    "\n",
    "for root, dirs, files in walk(path.join('..', 'data'), 'r'):\n",
    "     for file in files:\n",
    "        with open(path.join(root, file), 'rb') as input_stream:\n",
    "            if encounter_utility_file(file):\n",
    "                continue\n",
    "            conference = str(root + file).split('data/')[1].split('/')[0]\n",
    "            year = str(root).split('data/')[1].split('/')[1]\n",
    "            try:\n",
    "                add_paper_data(input_stream.read().decode('utf-8'), conference, year)\n",
    "            except UnicodeDecodeError:\n",
    "                if any(name in root for name in ['all', 'online']):\n",
    "                    search_files(root)\n",
    "                else:   \n",
    "                    continue # remove\n",
    "                    reader = PdfFileReader(input_stream)\n",
    "                    data[conference][year].append(reader.getPage(0).extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "with open('dialogue_2000-2001-2002.pickle', 'wb') as f:\n",
    "    dump(dict(data['Dialogue']), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
